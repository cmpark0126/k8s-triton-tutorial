apiVersion: apps/v1
kind: Deployment
metadata:
  name: server-1
spec:
  replicas: 2
  selector:
    matchLabels:
      app: server-1
  template:
    metadata:
      labels:
        app: server-1
    spec:
      serviceAccountName: s3-full-access-role
      containers:
        - name: server-1
          image: cmpark0126/eks-triton-test:23.04-py3
          command: [
              "tritonserver",
              "--model-repository",
              "s3://hf-s3/",
              "--allow-metrics",
              "true",
              "--allow-gpu-metrics",
              "true",
              "--log-verbose",
              "1"
            ]
          resources:
            limits:
              cpu: "3"
              memory: 10Gi
              nvidia.com/gpu: "1"
            requests:
              cpu: "3"
              memory: 10Gi
              nvidia.com/gpu: "1"
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: "node.kubernetes.io/instance-type"
                    operator: "In"
                    values: ["g4dn.xlarge"] # g4dn.xlarge for tesla t4, g5.xlarge for a10g
                  - key: "karpenter.sh/capacity-type"
                    operator: "In"
                    values: ["spot"]
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: server-2
spec:
  replicas: 2
  selector:
    matchLabels:
      app: server-2
  template:
    metadata:
      labels:
        app: server-2
    spec:
      serviceAccountName: s3-full-access-role
      containers:
        - name: server-2
          image: cmpark0126/eks-triton-test:23.04-py3
          command: [
              "tritonserver",
              "--model-repository",
              "s3://hf-s3/",
              "--allow-metrics",
              "true",
              "--allow-gpu-metrics",
              "true",
              "--log-verbose",
              "1"
            ]
          resources:
            limits:
              cpu: "3"
              memory: 10Gi
              nvidia.com/gpu: "1"
            requests:
              cpu: "3"
              memory: 10Gi
              nvidia.com/gpu: "1"
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: "node.kubernetes.io/instance-type"
                    operator: "In"
                    values: ["g4dn.xlarge"] # g4dn.xlarge for tesla t4, g5.xlarge for a10g
                  - key: "karpenter.sh/capacity-type"
                    operator: "In"
                    values: ["spot"]
